# -*- coding: utf-8 -*-
"""lecixon v4 web scrapper.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kCau8FxfNUOVvBRw8YMLXUftxvR6sAKb
"""

#!pip install streamlit pandas gnews transformers plotly torch
#untuk instal web scrapper
#install sastrawi dulu
#!pip install Sastrawi
#untuk word tokenize
#!pip install nltk
#import googletrans
#!pip install googletrans
#!pip install googletrans==4.0.0-rc1

#!pip install streamlit

"""Import Library"""

import pandas as pd
import numpy as np
import re
import string
import nltk.corpus
import csv
import matplotlib.pyplot as plt
import seaborn as sns
import streamlit as st

#from wordcloud import WordCloud
#from wordcloud import WordCloud, STOPWORDS
#from tensorflow.keras.preprocessing import text
from Sastrawi.Stemmer.StemmerFactory import StemmerFactory

import nltk
nltk.download('punkt_tab')
from nltk.tokenize import word_tokenize
nltk.download('stopwords')  # Download stopwords terlebih dahulu
from nltk.corpus import stopwords

import googletrans
from googletrans import Translator
import textblob
from textblob import TextBlob

"""Google news scrapper"""

#from transformers import pipeline
from gnews import GNews
import pandas as pd
import datetime

def process_keyword(keyword):
    # Ambil tanggal 7 hari lalu
    one_week_ago = datetime.datetime.now() - datetime.timedelta(days=7)

    # Ambil berita dari GNews
    news = GNews(language='id', country='ID', max_results=100)
    search_results = news.get_news(keyword)
    data = []
    for article in search_results:
        try:
            published_date = datetime.datetime.strptime(article['published date'], '%a, %d %b %Y %H:%M:%S %Z')
            if published_date > one_week_ago:
                data.append({
                    'title': article.get('title'),
                    'description': article.get('description'),
                    'url': article.get('url'),
                    'published_date': published_date,
                    'publisher': article.get('publisher', {}).get('title', None)
                })
        except Exception as e:
            continue  # Skip jika format tanggal error

    # Buat DataFrame
    df = pd.DataFrame(data)
    df_clean = df.drop_duplicates(subset='title')
    total_count = len(df_clean)
    return total_count, df_clean

# Streamlit app layout
st.title("News Sentiment Analysis Dashboard")

keyword_input = st.text_input("Enter a keyword to search for news", placeholder="Type a keyword...")

if st.button("Analyze"):
    if keyword_input:
        with st.spinner('Scraping and analyzing the data...'):
            positive_count, negative_count, neutral_count, total_count, df_clean = process_keyword(keyword_input)

        # Create plots
        fig_positive = go.Figure(go.Indicator(
            mode="gauge+number",
            value=positive_count,
            title={'text': "Positive Sentiment"},
            gauge={'axis': {'range': [0, total_count]},
                   'bar': {'color': "green"}}
        ))

        fig_negative = go.Figure(go.Indicator(
            mode="gauge+number",
            value=negative_count,
            title={'text': "Negative Sentiment"},
            gauge={'axis': {'range': [0, total_count]},
                   'bar': {'color': "red"}}
        ))

        fig_neutral = go.Figure(go.Indicator(
            mode="gauge+number",
            value=neutral_count,
            title={'text': "Neutral Sentiment"},
            gauge={'axis': {'range': [0, total_count]},
                   'bar': {'color': "yellow"}}
        ))

        fig_donut = go.Figure(go.Pie(
            labels=['Positive', 'Negative', 'Neutral'],
            values=[positive_count, negative_count, neutral_count],
            hole=0.5,
            marker=dict(colors=['green', 'red', 'yellow'])
        ))
        fig_donut.update_layout(title_text='Sentiment Distribution')

        # Create a horizontal layout using st.columns
        col1, col2, col3 = st.columns(3)

        # Display results in each column
        col1.plotly_chart(fig_positive, use_container_width=True)
        col2.plotly_chart(fig_negative, use_container_width=True)
        col3.plotly_chart(fig_neutral, use_container_width=True)

        st.plotly_chart(fig_donut, use_container_width=True)

        st.write(f"News articles found: {total_count}")

        # Show DataFrame
        st.dataframe(df_clean, use_container_width=True)

        # Download CSV
        csv = df_clean.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="Download CSV",
            data=csv,
            file_name='news_sentiment_analysis.csv',
            mime='text/csv',
        )
    else:
        st.error("Please enter a keyword.")


